<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reflect AI - Understand Your Conversations</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        .main-card {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            padding: 30px;
            margin-bottom: 20px;
        }

        .settings-section {
            margin-bottom: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 15px;
        }

        .settings-row {
            display: flex;
            gap: 20px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }

        .setting-group {
            flex: 1;
            min-width: 200px;
        }

        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 600;
            color: #555;
        }

        input, select, textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 16px;
            transition: border-color 0.3s;
        }

        input:focus, select:focus, textarea:focus {
            outline: none;
            border-color: #667eea;
        }

        .input-methods {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .method-btn {
            flex: 1;
            min-width: 150px;
            padding: 15px;
            border: 2px solid #e0e0e0;
            background: white;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s;
            text-align: center;
            font-weight: 600;
        }

        .method-btn.active {
            border-color: #667eea;
            background: #667eea;
            color: white;
        }

        .method-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .input-section {
            margin-bottom: 30px;
        }

        .recording-controls {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            align-items: center;
        }

        .record-btn {
            padding: 15px 30px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .record-btn.start {
            background: #28a745;
            color: white;
        }

        .record-btn.stop {
            background: #dc3545;
            color: white;
        }

        .record-btn:hover {
            transform: scale(1.05);
        }

        .record-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 8px;
            font-weight: 600;
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #28a745;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }

        .transcript-section {
            margin-bottom: 30px;
        }

        .transcript-box {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .speaker-line {
            margin-bottom: 10px;
            padding: 8px;
            border-radius: 5px;
            background: white;
            border-left: 4px solid #667eea;
        }

        .speaker-name {
            font-weight: bold;
            color: #667eea;
            margin-bottom: 5px;
        }

        .speaker-text {
            color: #333;
            line-height: 1.4;
        }

        .speaker-management {
            background: #e3f2fd;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .speaker-item {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 10px;
        }

        .speaker-label {
            min-width: 80px;
            font-weight: 600;
        }

        .speaker-name-input {
            flex: 1;
            max-width: 200px;
        }

        .is-me-checkbox {
            width: auto;
        }

        .action-buttons {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .action-btn {
            padding: 12px 25px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            flex: 1;
            min-width: 120px;
        }

        .action-btn.summary {
            background: #17a2b8;
            color: white;
        }

        .action-btn.analyze {
            background: #6f42c1;
            color: white;
        }

        .action-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }

        .action-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .conversation-management {
            margin-bottom: 30px;
        }

        .conversation-controls {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .conversation-btn {
            padding: 12px 25px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            flex: 1;
            min-width: 150px;
        }

        .conversation-btn.save {
            background: #28a745;
            color: white;
        }

        .conversation-btn.new {
            background: #6c757d;
            color: white;
        }

        .conversation-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }

        .conversation-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .saved-conversations-section {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
        }

        .saved-conversations-section h3 {
            margin-bottom: 20px;
            color: #333;
        }

        .saved-conversations-list {
            max-height: 400px;
            overflow-y: auto;
        }

        .conversation-item {
            background: white;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 10px;
            transition: all 0.3s;
        }

        .conversation-item:hover {
            border-color: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }

        .conversation-header {
            display: flex;
            justify-content: between;
            align-items: center;
            margin-bottom: 10px;
        }

        .conversation-title {
            font-weight: 600;
            color: #333;
            flex: 1;
        }

        .conversation-date {
            color: #666;
            font-size: 14px;
        }

        .conversation-preview {
            color: #555;
            font-size: 14px;
            margin-bottom: 10px;
            display: -webkit-box;
            -webkit-line-clamp: 2;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }

        .conversation-actions {
            display: flex;
            gap: 10px;
        }

        .conversation-action-btn {
            padding: 8px 15px;
            border: none;
            border-radius: 15px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .conversation-action-btn.load {
            background: #007bff;
            color: white;
        }

        .conversation-action-btn.delete {
            background: #dc3545;
            color: white;
        }

        .conversation-action-btn:hover {
            transform: scale(1.05);
        }

        .conversation-badge {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 12px;
            font-weight: 600;
            margin-right: 8px;
        }

        .conversation-badge.recorded {
            background: #28a745;
            color: white;
        }

        .conversation-badge.uploaded {
            background: #17a2b8;
            color: white;
        }

        .conversation-badge.typed {
            background: #6f42c1;
            color: white;
        }

        .current-conversation-indicator {
            background: #fff3cd;
            border: 2px solid #ffeaa7;
            border-radius: 10px;
            padding: 10px;
            margin-bottom: 20px;
            display: none;
        }

        .current-conversation-indicator.active {
            display: block;
        }

        .model-tooltip {
            margin-top: 8px;
            padding: 10px;
            background: #e8f4fd;
            border: 1px solid #bee5eb;
            border-radius: 8px;
            font-size: 14px;
            color: #0c5460;
            line-height: 1.4;
        }

        .model-tooltip strong {
            color: #084298;
        }

        .ai-model-info {
            background: #fff3cd;
            border: 2px solid #ffeaa7;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            font-size: 14px;
            color: #856404;
        }

        .ai-model-info .model-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-top: 10px;
        }

        .model-option {
            background: white;
            padding: 12px;
            border-radius: 8px;
            border: 2px solid #e0e0e0;
        }

        .model-option.selected {
            border-color: #667eea;
            background: #f8f9ff;
        }

        .model-option h4 {
            margin: 0 0 8px 0;
            color: #333;
        }

        .model-option p {
            margin: 0;
            font-size: 13px;
            color: #666;
        }

        @media (max-width: 768px) {
            .ai-model-info .model-comparison {
                grid-template-columns: 1fr;
                gap: 10px;
            }
        }

        .results-section {
            margin-top: 30px;
        }

        .result-box {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .result-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #333;
            margin-bottom: 15px;
        }

        .result-content {
            line-height: 1.6;
            color: #555;
        }

        .prompt-section {
            background: #fff3cd;
            border: 2px solid #ffeaa7;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .prompt-title {
            font-weight: 600;
            margin-bottom: 10px;
            color: #856404;
        }

        .prompt-textarea {
            height: 120px;
            resize: vertical;
        }

        .context-section {
            background: #d1ecf1;
            border: 2px solid #bee5eb;
            border-radius: 10px;
            padding: 20px;
            margin-top: 20px;
        }

        .loading {
            display: flex;
            align-items: center;
            gap: 10px;
            color: #666;
        }

        .spinner {
            width: 20px;
            height: 20px;
            border: 2px solid #f3f3f3;
            border-top: 2px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .hidden {
            display: none !important;
        }

        .error {
            background: #f8d7da;
            border: 2px solid #f5c6cb;
            color: #721c24;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }

        .success {
            background: #d4edda;
            border: 2px solid #c3e6cb;
            color: #155724;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .settings-row {
                flex-direction: column;
                gap: 10px;
            }
            
            .input-methods {
                flex-direction: column;
            }
            
            .recording-controls {
                flex-direction: column;
                align-items: stretch;
            }
            
            .action-buttons {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Reflect AI</h1>
            <p>Understand your conversations, discover yourself</p>
        </div>

        <div class="main-card">
            <!-- Settings Section -->
            <div class="settings-section">
                <h2>Settings</h2>
                <div class="settings-row">
                    <div class="setting-group">
                        <label for="userName">Your Name:</label>
                        <input type="text" id="userName" placeholder="Enter your name">
                    </div>
                    <div class="setting-group">
                        <label for="conversationLanguage">Conversation Language:</label>
                        <select id="conversationLanguage">
                            <option value="en">English</option>
                            <option value="he">Hebrew</option>
                        </select>
                    </div>
                    <div class="setting-group">
                        <label for="analysisLanguage">Analysis Language:</label>
                        <select id="analysisLanguage">
                            <option value="en">English</option>
                            <option value="he">Hebrew</option>
                        </select>
                    </div>
                    <div class="setting-group">
                        <label for="relationshipType">Relationship Type:</label>
                        <select id="relationshipType">
                            <option value="romantic">üíï Romantic Partners</option>
                            <option value="parent-child">üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Parent - Child</option>
                            <option value="friends">üë• Friends</option>
                            <option value="colleagues">üíº Colleagues</option>
                            <option value="family">üè† Family Members</option>
                            <option value="other">üîß Other (specify below)</option>
                        </select>
                    </div>
                </div>
                <div class="settings-row">
                    <div class="setting-group">
                        <label for="customRelationship">Custom Relationship (if "Other" selected):</label>
                        <input type="text" id="customRelationship" placeholder="e.g., therapist-client, teacher-student...">
                    </div>
                    <div class="setting-group">
                        <label for="aiModel">AI Model:</label>
                        <select id="aiModel">
                            <option value="gpt-3.5-turbo">‚ö° ChatGPT-3.5 (Fast & Free)</option>
                            <option value="gpt-4">üîç ChatGPT-4 (Deep & Accurate)</option>
                        </select>
                        <div class="model-tooltip" id="modelTooltip">
                            <strong>‚ö° ChatGPT-3.5:</strong> Quick response, lower cost. Great for short or casual analysis.
                        </div>
                    </div>
                </div>
            </div>

            <!-- Input Method Selection -->
            <div class="input-methods">
                <div class="method-btn active" data-method="record">
                    üéôÔ∏è Record Live
                </div>
                <div class="method-btn" data-method="upload">
                    üìÅ Upload Audio
                </div>
                <div class="method-btn" data-method="type">
                    ‚úçÔ∏è Type/Describe
                </div>
            </div>

            <!-- Recording Section -->
            <div class="input-section" id="recordSection">
                <div class="recording-controls">
                    <button class="record-btn start" id="startRecording">
                        üéôÔ∏è Start Recording
                    </button>
                    <button class="record-btn stop hidden" id="stopRecording">
                        ‚èπÔ∏è Stop Recording
                    </button>
                    <div class="status-indicator hidden" id="recordingStatus">
                        <div class="status-dot"></div>
                        <span>Recording...</span>
                    </div>
                </div>
                <audio id="audioPlayback" controls class="hidden" style="width: 100%; margin-top: 10px;"></audio>
            </div>

            <!-- Upload Section -->
            <div class="input-section hidden" id="uploadSection">
                <label for="audioFile">Upload Audio File:</label>
                <input type="file" id="audioFile" accept="audio/*">
            </div>

            <!-- Type Section -->
            <div class="input-section hidden" id="typeSection">
                <label for="conversationText">Type or Describe Your Conversation:</label>
                <textarea id="conversationText" placeholder="Describe your conversation here..." rows="6"></textarea>
            </div>

            <!-- Transcript Section -->
            <div class="transcript-section">
                <h3>Conversation Transcript</h3>
                <div class="transcript-box" id="transcriptBox">
                    <p style="color: #666; text-align: center;">Your conversation transcript will appear here...</p>
                </div>
            </div>

            <!-- Speaker Management -->
            <div class="speaker-management hidden" id="speakerManagement">
                <h3>Identify Speakers</h3>
                <p style="margin-bottom: 15px;">Name the speakers and select which one is you:</p>
                <div id="speakerList"></div>
            </div>

            <!-- Action Buttons -->
            <div class="action-buttons">
                <button class="action-btn summary" id="summaryBtn" disabled>
                    üìã Generate Summary
                </button>
                <button class="action-btn analyze" id="analyzeBtn" disabled>
                    üîç Analyze My Behavior
                </button>
                <button class="action-btn" id="testConnectionBtn" style="background: #fd7e14; color: white;">
                    üß™ Test OpenAI Connection
                </button>
            </div>

            <!-- AI Model Information -->
            <div class="ai-model-info">
                <strong>ü§ñ AI Model Selection:</strong> Choose the right model for your needs
                <div class="model-comparison">
                    <div class="model-option" id="gpt35Option">
                        <h4>‚ö° ChatGPT-3.5</h4>
                        <p><strong>Fast & Efficient:</strong> Quick response (2-5 sec), lower cost. Handles conversations up to 1 hour well. Great for quick insights.</p>
                    </div>
                    <div class="model-option" id="gpt4Option">
                        <h4>üîç ChatGPT-4</h4>
                        <p><strong>Deep & Comprehensive:</strong> Slower response (10-60 sec), higher cost. Excellent for 2+ hour conversations, complex emotions, and nuanced analysis.</p>
                    </div>
                </div>
            </div>

            <!-- Conversation Management -->
            <div class="conversation-management">
                <!-- Current Conversation Indicator -->
                <div class="current-conversation-indicator" id="currentConversationIndicator">
                    <strong>üìù Current Conversation:</strong> New conversation
                </div>
                
                <div class="conversation-controls">
                    <button class="conversation-btn save" id="saveConversationBtn" disabled>
                        üíæ Save Conversation
                    </button>
                    <button class="conversation-btn new" id="newConversationBtn">
                        üÜï New Conversation
                    </button>
                </div>
                
                <div class="saved-conversations-section" id="savedConversationsSection">
                    <h3>üí¨ Saved Conversations</h3>
                    <div class="saved-conversations-list" id="savedConversationsList">
                        <p style="color: #666; text-align: center; padding: 20px;">No saved conversations yet...</p>
                    </div>
                </div>
            </div>

            <!-- AI Prompt Customization -->
            <div class="prompt-section">
                <div class="prompt-title">üéØ Customize Summary Prompt</div>
                <textarea id="summaryPrompt" class="prompt-textarea" placeholder="Enter your custom prompt for summary generation...">You are an expert conversation analyst. Create a comprehensive summary of the following conversation for the user. Address the user directly in second person throughout your summary.

Please organize your summary by:
- Main topics discussed in your conversation
- Key points and decisions made
- Important insights or revelations that came up
- Any action items or next steps mentioned

Write in a conversational tone, addressing the user as "you" and referring to their specific contributions to the discussion. Be thorough but concise.</textarea>
                
                <div class="prompt-title" style="margin-top: 20px;">üéØ Customize Analysis Prompt</div>
                <textarea id="aiPrompt" class="prompt-textarea" placeholder="Enter your custom prompt for AI analysis...">You are an expert conversation analyst and behavioral psychologist. Analyze the following conversation transcript, focusing specifically on the user's behavior, communication patterns, and social dynamics. Address the user directly in second person throughout your analysis.

Please provide insights about:
- Your communication style and patterns
- How you interact with others in the conversation
- Any behavioral insights or areas for improvement you might consider
- Underlying issues or patterns you might want to be aware of
- Constructive advice for your future social interactions

Write your analysis in a conversational, flowing paragraph addressing the user directly as "you." Be empathetic but honest, focusing on growth and self-awareness.</textarea>

                <div class="prompt-title" style="margin-top: 20px;">üéØ Customize Continue Conversation Prompt</div>
                <textarea id="continuePrompt" class="prompt-textarea" placeholder="Enter your custom prompt for continuing analysis...">You are continuing a conversation analysis based on the user's additional context and questions. Build upon the previous analysis while addressing their new input. Keep the same empathetic, conversational tone and continue addressing them in second person.

Please:
- Address their specific questions or context
- Provide additional insights based on their input
- Connect their new thoughts to the previous analysis
- Offer practical advice or perspectives
- Maintain the focus on growth and self-awareness

Continue the flowing, conversational style and be responsive to their specific needs and questions.</textarea>
                
                <div style="margin-top: 10px; font-size: 14px; color: #666;">
                    <strong>Note:</strong> These prompts are sent to OpenAI exactly as written. The system automatically adds language instructions and your transcript.
                </div>
            </div>

            <!-- Results Section -->
            <div class="results-section">
                <div class="result-box hidden" id="summaryResult">
                    <div class="result-title">üìã Conversation Summary</div>
                    <div class="result-content" id="summaryContent"></div>
                </div>

                <div class="result-box hidden" id="analysisResult">
                    <div class="result-title">üîç Your Behavioral Analysis</div>
                    <div class="result-content" id="analysisContent"></div>
                </div>

                <div class="context-section hidden" id="contextSection">
                    <label for="contextInput">Add more context or continue the conversation:</label>
                    <textarea id="contextInput" rows="3" placeholder="Add your thoughts, context, or ask follow-up questions..."></textarea>
                    <button class="action-btn analyze" id="continueBtn" style="margin-top: 10px;">
                        üí¨ Continue Analysis
                    </button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let mediaRecorder;
        let audioChunks = [];
        let currentTranscript = '';
        let speakers = [];
        let currentMethod = 'record';
        let isRecording = false;
        let liveTranscriptionInterval;
        let recognitionService;
        let currentConversationId = null;
        let savedConversations = [];

        // Backend Configuration - Vercel API routes
        const BACKEND_URL = window.location.origin;

        // Initialize the application
        document.addEventListener('DOMContentLoaded', function() {
            initializeEventListeners();
            setupMethodSwitching();
            testBackendConnection();
            loadSavedConversations();
            updateModelTooltip();
        });

        async function testBackendConnection() {
            try {
                const response = await fetch(`${BACKEND_URL}/api/health`);
                if (response.ok) {
                    const data = await response.json();
                    console.log('‚úÖ Backend connected successfully:', data);
                    
                    // Show success indicator
                    showSuccess('üü¢ Backend server connected - Secure transcription and analysis available!');
                } else {
                    throw new Error(`Server responded with status ${response.status}`);
                }
            } catch (error) {
                console.log('‚ùå Backend connection failed:', error.message);
                
                // Show warning indicator
                showError('üü° Backend offline - Please start the backend server for full functionality');
            }
        }

        function initializeEventListeners() {
            console.log('üîß Initializing event listeners...');
            
            document.getElementById('startRecording').addEventListener('click', startRecording);
            document.getElementById('stopRecording').addEventListener('click', stopRecording);
            document.getElementById('audioFile').addEventListener('change', handleFileUpload);
            document.getElementById('conversationText').addEventListener('input', handleTextInput);
            
            // Check if buttons exist before adding listeners
            const summaryBtn = document.getElementById('summaryBtn');
            const analyzeBtn = document.getElementById('analyzeBtn');
            const continueBtn = document.getElementById('continueBtn');
            const saveBtn = document.getElementById('saveConversationBtn');
            const newBtn = document.getElementById('newConversationBtn');
            const testBtn = document.getElementById('testConnectionBtn');
            const modelSelect = document.getElementById('aiModel');
            
            if (summaryBtn) {
                summaryBtn.addEventListener('click', generateSummary);
                console.log('‚úÖ Summary button listener added');
            } else {
                console.error('‚ùå Summary button not found');
            }
            
            if (analyzeBtn) {
                analyzeBtn.addEventListener('click', analyzeConversation);
                console.log('‚úÖ Analyze button listener added');
            } else {
                console.error('‚ùå Analyze button not found');
            }
            
            if (continueBtn) {
                continueBtn.addEventListener('click', continueAnalysis);
                console.log('‚úÖ Continue button listener added');
            } else {
                console.error('‚ùå Continue button not found');
            }
            
            if (saveBtn) {
                saveBtn.addEventListener('click', saveConversation);
                console.log('‚úÖ Save button listener added');
            } else {
                console.error('‚ùå Save button not found');
            }
            
            if (newBtn) {
                newBtn.addEventListener('click', startNewConversation);
                console.log('‚úÖ New conversation button listener added');
            } else {
                console.error('‚ùå New conversation button not found');
            }
            
            if (testBtn) {
                testBtn.addEventListener('click', testOpenAIConnection);
                console.log('‚úÖ Test connection button listener added');
            } else {
                console.error('‚ùå Test connection button not found');
            }
            
            if (modelSelect) {
                modelSelect.addEventListener('change', updateModelTooltip);
                console.log('‚úÖ Model select listener added');
            } else {
                console.error('‚ùå Model select not found');
            }
            
            console.log('üîß Event listeners initialization complete');
        }

        function setupMethodSwitching() {
            document.querySelectorAll('.method-btn').forEach(btn => {
                btn.addEventListener('click', function() {
                    // Update active button
                    document.querySelectorAll('.method-btn').forEach(b => b.classList.remove('active'));
                    this.classList.add('active');
                    
                    // Hide all sections
                    document.querySelectorAll('.input-section').forEach(section => {
                        section.classList.add('hidden');
                    });
                    
                    // Show selected section
                    currentMethod = this.dataset.method;
                    document.getElementById(currentMethod + 'Section').classList.remove('hidden');
                    
                    // Reset transcript
                    resetTranscript();
                });
            });
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Initialize live transcription
                startLiveTranscription();
                
                // Use audio formats that Whisper supports
                let options = {};
                if (MediaRecorder.isTypeSupported('audio/wav')) {
                    options = { mimeType: 'audio/wav' };
                } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                    options = { mimeType: 'audio/mp4' };
                } else if (MediaRecorder.isTypeSupported('audio/ogg')) {
                    options = { mimeType: 'audio/ogg' };
                } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                    options = { mimeType: 'audio/webm' };
                }
                
                mediaRecorder = new MediaRecorder(stream, options);
                console.log('üéôÔ∏è Recording with format:', mediaRecorder.mimeType);
                
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    // Stop live transcription
                    stopLiveTranscription();
                    
                    // Create blob with appropriate format
                    const mimeType = mediaRecorder.mimeType || 'audio/wav';
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    
                    console.log('üìÑ Audio blob type:', audioBlob.type);
                    console.log('üìä Audio blob size:', audioBlob.size, 'bytes');
                    
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audioElement = document.getElementById('audioPlayback');
                    audioElement.src = audioUrl;
                    audioElement.classList.remove('hidden');
                    
                    // Show final transcription process
                    showFinalTranscription();
                    await transcribeAudio(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                
                document.getElementById('startRecording').classList.add('hidden');
                document.getElementById('stopRecording').classList.remove('hidden');
                document.getElementById('recordingStatus').classList.remove('hidden');
                
            } catch (error) {
                showError('Error accessing microphone: ' + error.message);
            }
        }

        function startLiveTranscription() {
            // Check for Web Speech API support
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognitionService = new SpeechRecognition();
                
                const conversationLanguage = document.getElementById('conversationLanguage').value;
                recognitionService.lang = conversationLanguage === 'he' ? 'he-IL' : 'en-US';
                recognitionService.continuous = true;
                recognitionService.interimResults = true;
                
                let finalTranscript = '';
                
                recognitionService.onresult = (event) => {
                    let interimTranscript = '';
                    
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript + ' ';
                        } else {
                            interimTranscript += transcript;
                        }
                    }
                    
                    // Update live transcript display
                    const transcriptBox = document.getElementById('transcriptBox');
                    transcriptBox.innerHTML = `
                        <div style="background: #e8f5e8; padding: 15px; border-radius: 8px; margin-bottom: 10px;">
                            <p><strong>üéôÔ∏è Live Transcription:</strong></p>
                            <p style="margin-top: 10px; color: #333;">${finalTranscript}</p>
                            <p style="margin-top: 5px; color: #666; font-style: italic;">${interimTranscript}</p>
                        </div>
                        <div style="background: #fff3cd; padding: 10px; border-radius: 8px; font-size: 14px; color: #856404;">
                            <p><strong>Note:</strong> This is a live preview. Final transcription with speaker identification will be processed when you stop recording.</p>
                        </div>
                    `;
                };
                
                recognitionService.onerror = (event) => {
                    console.log('Live transcription error:', event.error);
                    if (event.error === 'not-allowed') {
                        showError('Microphone access denied. Please allow microphone access for live transcription.');
                    }
                };
                
                recognitionService.onend = () => {
                    if (isRecording) {
                        // Restart if still recording
                        setTimeout(() => {
                            if (isRecording) {
                                recognitionService.start();
                            }
                        }, 1000);
                    }
                };
                
                try {
                    recognitionService.start();
                } catch (error) {
                    console.log('Could not start live transcription:', error);
                }
            } else {
                // Fallback to status message
                const transcriptBox = document.getElementById('transcriptBox');
                transcriptBox.innerHTML = `
                    <div style="background: #e3f2fd; padding: 15px; border-radius: 8px; text-align: center;">
                        <p><strong>üéôÔ∏è Recording in progress...</strong></p>
                        <p style="margin-top: 10px; color: #666;">Live transcription not available in this browser. Full transcript will appear when you stop recording.</p>
                    </div>
                `;
            }
        }

        function stopLiveTranscription() {
            if (recognitionService) {
                recognitionService.stop();
                recognitionService = null;
            }
        }

        function showFinalTranscription() {
            const transcriptBox = document.getElementById('transcriptBox');
            transcriptBox.innerHTML = `
                <div style="background: #fff3cd; padding: 15px; border-radius: 8px; text-align: center;">
                    <p><strong>ü§ñ Processing final transcription...</strong></p>
                    <p style="margin-top: 10px; color: #666;">Using OpenAI Whisper for accurate transcription with speaker identification.</p>
                </div>
            `;
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop live transcription
                stopLiveTranscription();
                
                // Update UI
                document.getElementById('startRecording').classList.remove('hidden');
                document.getElementById('stopRecording').classList.add('hidden');
                document.getElementById('recordingStatus').classList.add('hidden');
            }
        }

        // Remove the old showLiveTranscription function as it's now integrated into startRecording

        async function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                // Show the uploaded file info
                const transcriptBox = document.getElementById('transcriptBox');
                transcriptBox.innerHTML = `
                    <div style="background: #e3f2fd; padding: 15px; border-radius: 8px; text-align: center; margin-bottom: 15px;">
                        <p><strong>üìÅ File uploaded:</strong> ${file.name}</p>
                        <p style="color: #666; margin-top: 5px;">File size: ${(file.size / 1024 / 1024).toFixed(2)} MB</p>
                        <p style="color: #28a745; margin-top: 10px;">
                            üöÄ Connecting to transcription server...
                        </p>
                    </div>
                `;
                
                // Transcribe the uploaded file
                await transcribeAudio(file);
            }
        }

        function handleTextInput() {
            const text = document.getElementById('conversationText').value;
            if (text.trim()) {
                // Parse the text into speaker format
                const lines = text.split('\n').filter(line => line.trim());
                currentTranscript = lines.join('\n');
                displayTranscript(currentTranscript);
                enableActionButtons();
            }
        }

        async function transcribeAudio(audioBlob) {
            try {
                showLoading('Transcribing with Whisper AI...');
                
                // Test backend connection
                const healthCheck = await fetch(`${BACKEND_URL}/api/health`);
                if (!healthCheck.ok) {
                    throw new Error('Backend server is not responding');
                }
                
                // Create FormData for Whisper backend
                const formData = new FormData();
                
                // Determine appropriate filename
                let filename = 'recording.wav';
                if (audioBlob.type.includes('mp4')) {
                    filename = 'recording.mp4';
                } else if (audioBlob.type.includes('ogg')) {
                    filename = 'recording.ogg';
                } else if (audioBlob.type.includes('webm')) {
                    filename = 'recording.webm';
                }
                
                console.log('üì§ Uploading as:', filename, 'Type:', audioBlob.type);
                
                formData.append('audio', audioBlob, filename);
                formData.append('language', document.getElementById('conversationLanguage').value);
                
                // Send to Whisper backend
                const response = await fetch(`${BACKEND_URL}/api/transcribe`, {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const errorText = await response.text();
                    let errorData;
                    try {
                        errorData = JSON.parse(errorText);
                    } catch {
                        errorData = { message: errorText };
                    }
                    throw new Error(errorData.message || `Transcription failed: ${response.status}`);
                }
                
                const data = await response.json();
                
                if (data.status === 'completed') {
                    currentTranscript = data.transcript;
                    displayTranscript(currentTranscript);
                    enableActionButtons();
                    showSuccess(`‚úÖ Transcription completed! Language: ${data.language}, Service: ${data.transcription_service}`);
                } else {
                    throw new Error('Transcription incomplete: ' + data.message);
                }
                
            } catch (error) {
                console.error('Transcription error:', error);
                hideLoading();
                
                if (error.message.includes('Backend server')) {
                    showError('‚ùå Cannot connect to backend server. Please make sure it\'s running.');
                } else if (error.message.includes('Unrecognized file format')) {
                    showError('‚ùå Audio format not supported. Try using "Upload Audio" with an MP3 or WAV file.');
                } else {
                    showError('Transcription failed: ' + error.message);
                }
            } finally {
                hideLoading();
            }
        }

        function updateModelTooltip() {
            const selectedModel = document.getElementById('aiModel').value;
            const tooltip = document.getElementById('modelTooltip');
            const gpt35Option = document.getElementById('gpt35Option');
            const gpt4Option = document.getElementById('gpt4Option');
            
            // Update tooltip text
            if (selectedModel === 'gpt-4') {
                tooltip.innerHTML = '<strong>üîç ChatGPT-4:</strong> Slower but more intelligent. Perfect for long conversations (2+ hours), complex emotions, and deep psychological insights.';
                tooltip.style.background = '#f8e6ff';
                tooltip.style.borderColor = '#d4c5f9';
                tooltip.style.color = '#5a2d82';
                
                // Update visual selection
                gpt4Option.classList.add('selected');
                gpt35Option.classList.remove('selected');
            } else {
                tooltip.innerHTML = '<strong>‚ö° ChatGPT-3.5:</strong> Quick response, lower cost. Handles conversations up to 1 hour well. Great for fast insights.';
                tooltip.style.background = '#e8f4fd';
                tooltip.style.borderColor = '#bee5eb';
                tooltip.style.color = '#0c5460';
                
                // Update visual selection
                gpt35Option.classList.add('selected');
                gpt4Option.classList.remove('selected');
            }
        }

        function displayTranscript(transcript) {
            const transcriptBox = document.getElementById('transcriptBox');
            const lines = transcript.split('\n').filter(line => line.trim());
            
            transcriptBox.innerHTML = '';
            
            const uniqueSpeakers = new Set();
            
            lines.forEach(line => {
                const speakerMatch = line.match(/^(Speaker [A-Z]|[^:]+):\s*(.+)$/);
                if (speakerMatch) {
                    const speaker = speakerMatch[1];
                    const text = speakerMatch[2];
                    uniqueSpeakers.add(speaker);
                    
                    const speakerLine = document.createElement('div');
                    speakerLine.className = 'speaker-line';
                    speakerLine.innerHTML = `
                        <div class="speaker-name">${speaker}</div>
                        <div class="speaker-text">${text}</div>
                    `;
                    transcriptBox.appendChild(speakerLine);
                }
            });
            
            // Update speaker management
            updateSpeakerManagement(Array.from(uniqueSpeakers));
        }

        function updateSpeakerManagement(speakerList) {
            speakers = speakerList;
            const speakerManagement = document.getElementById('speakerManagement');
            const speakerListDiv = document.getElementById('speakerList');
            
            if (speakers.length > 0) {
                speakerManagement.classList.remove('hidden');
                speakerListDiv.innerHTML = '';
                
                speakers.forEach((speaker, index) => {
                    const speakerItem = document.createElement('div');
                    speakerItem.className = 'speaker-item';
                    speakerItem.innerHTML = `
                        <div class="speaker-label">${speaker}</div>
                        <input type="text" class="speaker-name-input" placeholder="Enter name..." value="${speaker}">
                        <label>
                            <input type="radio" name="isMe" class="is-me-checkbox" value="${index}">
                            This is me
                        </label>
                    `;
                    speakerListDiv.appendChild(speakerItem);
                });
            }
        }

        function enableActionButtons() {
            document.getElementById('summaryBtn').disabled = false;
            document.getElementById('analyzeBtn').disabled = false;
            document.getElementById('saveConversationBtn').disabled = false;
        }

        function resetTranscript() {
            currentTranscript = '';
            currentConversationId = null;
            document.getElementById('transcriptBox').innerHTML = '<p style="color: #666; text-align: center;">Your conversation transcript will appear here...</p>';
            document.getElementById('speakerManagement').classList.add('hidden');
            document.getElementById('summaryResult').classList.add('hidden');
            document.getElementById('analysisResult').classList.add('hidden');
            document.getElementById('contextSection').classList.add('hidden');
            document.getElementById('summaryBtn').disabled = true;
            document.getElementById('analyzeBtn').disabled = true;
            document.getElementById('saveConversationBtn').disabled = true;
            updateCurrentConversationIndicator();
        }

        async function generateSummary() {
            console.log('üìã Generate Summary button clicked');
            
            if (!currentTranscript) {
                showError('No transcript available to summarize.');
                return;
            }
            
            console.log('üìù Transcript available, proceeding with summary...');
            
            try {
                showLoading('Generating summary...');
                
                const analysisLanguage = document.getElementById('analysisLanguage').value;
                const userName = document.getElementById('userName').value || 'User';
                const customSummaryPrompt = document.getElementById('summaryPrompt').value;
                const relationshipType = document.getElementById('relationshipType').value;
                const customRelationship = document.getElementById('customRelationship').value;
                
                // Get speaker information
                const { namedSpeakers, selectedSpeaker } = getSpeakerNames();
                const namedTranscript = createNamedTranscript();
                
                let summaryPrompt;
                let relationshipContext = '';
                
                // Determine relationship context
                if (relationshipType === 'other' && customRelationship.trim()) {
                    relationshipContext = customRelationship.trim();
                } else {
                    const relationshipMap = {
                        'romantic': analysisLanguage === 'he' ? '◊ñ◊ï◊í ◊®◊ï◊û◊†◊ò◊ô' : 'romantic partners',
                        'parent-child': analysisLanguage === 'he' ? '◊î◊ï◊®◊î ◊ï◊ô◊ú◊ì' : 'parent and child',
                        'friends': analysisLanguage === 'he' ? '◊ó◊ë◊®◊ô◊ù' : 'friends',
                        'colleagues': analysisLanguage === 'he' ? '◊¢◊û◊ô◊™◊ô◊ù ◊ú◊¢◊ë◊ï◊ì◊î' : 'work colleagues',
                        'family': analysisLanguage === 'he' ? '◊ë◊†◊ô ◊û◊©◊§◊ó◊î' : 'family members'
                    };
                    relationshipContext = relationshipMap[relationshipType] || (analysisLanguage === 'he' ? '◊ê◊†◊©◊ô◊ù' : 'people');
                }
                
                if (analysisLanguage === 'he') {
                    // Native Hebrew prompt for summary
                    summaryPrompt = `◊ê◊™◊î ◊û◊ï◊û◊ó◊î ◊ú◊†◊ô◊™◊ï◊ó ◊©◊ô◊ó◊ï◊™ ◊ï◊û◊ê◊û◊ü ◊ê◊ô◊©◊ô. ◊ê◊†◊ô ◊®◊ï◊¶◊î ◊©◊™◊õ◊ô◊ü ◊ú◊ô ◊°◊ô◊õ◊ï◊ù ◊ë◊®◊ï◊® ◊ï◊©◊ô◊û◊ï◊©◊ô ◊©◊ú ◊î◊©◊ô◊ó◊î ◊©◊ú◊ô. ◊ì◊ë◊® ◊ê◊ú◊ô◊ô ◊ô◊©◊ô◊®◊ï◊™ ◊ë◊í◊ï◊£ ◊©◊†◊ô ◊ë◊¢◊ë◊®◊ô◊™ ◊ò◊ë◊¢◊ô◊™ ◊ï◊©◊ï◊ò◊§◊™.

◊î◊©◊ô◊ó◊î ◊î◊ñ◊ê◊™ ◊î◊ô◊ê ◊ë◊ô◊ü ${relationshipContext}. ◊ß◊ó ◊ê◊™ ◊ñ◊î ◊ë◊ó◊©◊ë◊ï◊ü ◊ë◊°◊ô◊õ◊ï◊ù. ${selectedSpeaker ? `◊©◊û◊ô ${userName} ◊ï◊ê◊†◊ô ◊î◊ï◊ê ${selectedSpeaker} ◊ë◊©◊ô◊ó◊î.` : `◊©◊û◊ô ${userName}.`}

◊ê◊†◊ô ◊®◊ï◊¶◊î ◊©◊™◊ê◊®◊í◊ü ◊ê◊™ ◊î◊°◊ô◊õ◊ï◊ù ◊ú◊§◊ô:
- ◊î◊†◊ï◊©◊ê◊ô◊ù ◊î◊¢◊ô◊ß◊®◊ô◊ô◊ù ◊©◊ì◊ô◊ë◊®◊†◊ï ◊¢◊ú◊ô◊î◊ù
- ◊†◊ß◊ï◊ì◊ï◊™ ◊ó◊©◊ï◊ë◊ï◊™ ◊ï◊î◊ó◊ú◊ò◊ï◊™ ◊©◊î◊™◊ß◊ë◊ú◊ï
- ◊™◊ï◊ë◊†◊ï◊™ ◊ê◊ï ◊ì◊ë◊®◊ô◊ù ◊ó◊ì◊©◊ô◊ù ◊©◊¢◊ú◊ï ◊ë◊©◊ô◊ó◊î
- ◊û◊©◊ô◊û◊ï◊™ ◊ê◊ï ◊¶◊¢◊ì◊ô◊ù ◊î◊ë◊ê◊ô◊ù ◊©◊î◊ï◊ñ◊õ◊®◊ï

◊õ◊™◊ï◊ë ◊ë◊ò◊ï◊ü ◊ê◊ô◊©◊ô ◊ï◊ó◊ù, ◊§◊†◊î ◊ê◊ú◊ô◊ô ◊õ"◊ê◊™◊î" ◊ï◊î◊™◊ô◊ô◊ó◊° ◊ú◊™◊®◊ï◊û◊î ◊©◊ú◊ô ◊ú◊©◊ô◊ó◊î. ◊™◊ü ◊ú◊ô ◊°◊ô◊õ◊ï◊ù ◊û◊§◊ï◊®◊ò ◊ê◊ë◊ú ◊ú◊ê ◊ê◊®◊ï◊ö ◊û◊ì◊ô. ◊î◊©◊™◊û◊© ◊ë◊©◊û◊ï◊™ ◊î◊ê◊û◊ô◊™◊ô◊ô◊ù ◊©◊ú ◊î◊ê◊†◊©◊ô◊ù ◊ë◊©◊ô◊ó◊î.

◊™◊û◊ú◊ô◊ú ◊î◊©◊ô◊ó◊î:
${namedTranscript}`;
                } else {
                    // Enhanced English prompt for summary
                    summaryPrompt = `You are an expert conversation analyst and personal coach. I want you to create a clear and useful summary of my conversation. Speak to me directly in second person with natural, flowing English.

This conversation is between ${relationshipContext}. Keep this relationship context in mind for your summary. ${selectedSpeaker ? `My name is ${userName} and I am ${selectedSpeaker} in this conversation.` : `My name is ${userName}.`}

${customSummaryPrompt}

Use the actual names of people in the conversation when referring to them.

Conversation transcript:
${namedTranscript}`;
                }
                
                const response = await fetch(`${BACKEND_URL}/api/analyze`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        prompt: summaryPrompt,
                        maxTokens: selectedModel === 'gpt-4' ? 3000 : 2000, // Higher limits for summaries
                        language: analysisLanguage,
                        model: selectedModel
                    })
                });
                
                if (!response.ok) {
                    let errorData;
                    try {
                        // Clone the response to avoid "body stream already read" error
                        const responseClone = response.clone();
                        errorData = await responseClone.json();
                    } catch {
                        // If JSON parsing fails, read as text
                        try {
                            const errorText = await response.text();
                            errorData = { message: errorText || 'Summary generation failed' };
                        } catch {
                            errorData = { message: 'Summary generation failed' };
                        }
                    }
                    throw new Error(errorData.message || 'Summary generation failed');
                }
                
                const data = await response.json();
                
                document.getElementById('summaryContent').innerHTML = data.response.replace(/\n/g, '<br>');
                document.getElementById('summaryResult').classList.remove('hidden');
                
                // Auto-save if conversation already exists
                if (currentConversationId) {
                    saveConversation();
                }
                
            } catch (error) {
                console.error('Summary error:', error);
                if (error.message.includes('fetch')) {
                    showError('Cannot connect to analysis server. Please make sure the backend server is running.');
                } else {
                    showError('Error generating summary: ' + error.message);
                }
            } finally {
                hideLoading();
            }
        }

        async function analyzeConversation() {
            console.log('üîç Analyze Conversation button clicked');
            
            if (!currentTranscript) {
                showError('No transcript available to analyze.');
                return;
            }
            
            console.log('üìù Transcript available, proceeding with analysis...');
            
            const userName = document.getElementById('userName').value || 'User';
            const customPrompt = document.getElementById('aiPrompt').value;
            const analysisLanguage = document.getElementById('analysisLanguage').value;
            const relationshipType = document.getElementById('relationshipType').value;
            const customRelationship = document.getElementById('customRelationship').value;
            
            // Get speaker information
            const { namedSpeakers, selectedSpeaker } = getSpeakerNames();
            const namedTranscript = createNamedTranscript();
            
            try {
                showLoading('Analyzing your conversation...');
                
                let analysisPrompt;
                let relationshipContext = '';
                
                // Determine relationship context
                if (relationshipType === 'other' && customRelationship.trim()) {
                    relationshipContext = customRelationship.trim();
                } else {
                    const relationshipMap = {
                        'romantic': analysisLanguage === 'he' ? '◊ñ◊ï◊í ◊®◊ï◊û◊†◊ò◊ô' : 'romantic partners',
                        'parent-child': analysisLanguage === 'he' ? '◊î◊ï◊®◊î ◊ï◊ô◊ú◊ì' : 'parent and child',
                        'friends': analysisLanguage === 'he' ? '◊ó◊ë◊®◊ô◊ù' : 'friends',
                        'colleagues': analysisLanguage === 'he' ? '◊¢◊û◊ô◊™◊ô◊ù ◊ú◊¢◊ë◊ï◊ì◊î' : 'work colleagues',
                        'family': analysisLanguage === 'he' ? '◊ë◊†◊ô ◊û◊©◊§◊ó◊î' : 'family members'
                    };
                    relationshipContext = relationshipMap[relationshipType] || (analysisLanguage === 'he' ? '◊ê◊†◊©◊ô◊ù' : 'people');
                }
                
                if (analysisLanguage === 'he') {
                    // Native Hebrew prompt - natural and coach-like
                    analysisPrompt = `◊ê◊™◊î ◊û◊ê◊û◊ü ◊ê◊ô◊©◊ô ◊ï◊§◊°◊ô◊õ◊ï◊ú◊ï◊í ◊û◊†◊ï◊°◊î ◊©◊û◊™◊û◊ó◊î ◊ë◊†◊ô◊™◊ï◊ó ◊™◊ß◊©◊ï◊®◊™ ◊ï◊ô◊ó◊°◊ô◊ù. ◊ê◊™◊î ◊ì◊ï◊ë◊® ◊¢◊ë◊®◊ô◊™ ◊©◊§◊™ ◊ê◊ù ◊ï◊û◊™◊ë◊ò◊ê ◊ë◊¶◊ï◊®◊î ◊ò◊ë◊¢◊ô◊™ ◊ï◊ó◊û◊î. ◊™◊§◊ß◊ô◊ì◊ö ◊ú◊¢◊ñ◊ï◊® ◊ú◊ê◊†◊©◊ô◊ù ◊ú◊î◊ë◊ô◊ü ◊ê◊™ ◊¢◊¶◊û◊ù ◊ò◊ï◊ë ◊ô◊ï◊™◊® ◊ì◊®◊ö ◊î◊ì◊®◊ö ◊©◊ë◊î ◊î◊ù ◊û◊™◊ß◊©◊®◊ô◊ù.

◊î◊©◊ô◊ó◊î ◊©◊ú◊§◊†◊ô◊ö ◊î◊ô◊ê ◊ë◊ô◊ü ${relationshipContext}. ◊©◊û◊ô ${userName} ◊ï◊ê◊†◊ô ◊®◊ï◊¶◊î ◊©◊™◊†◊™◊ó ◊ê◊™ ◊î◊™◊†◊î◊í◊ï◊™ ◊î◊™◊ß◊©◊ï◊®◊™◊ô◊™ ◊©◊ú◊ô ◊ï◊™◊¢◊ñ◊ï◊® ◊ú◊ô ◊ú◊î◊ë◊ô◊ü ◊ê◊ô◊ö ◊ê◊†◊ô ◊§◊ï◊¢◊ú ◊ë◊ô◊ó◊°◊ô◊ù.

${selectedSpeaker ? `◊ê◊†◊ô ◊î◊ï◊ê ${selectedSpeaker} ◊ë◊©◊ô◊ó◊î ◊î◊ñ◊ê◊™. ◊î◊™◊û◊ß◊ì ◊ë◊†◊ô◊™◊ï◊ó ◊©◊ú◊ô ◊°◊§◊¶◊ô◊§◊ô◊™ - ◊ê◊ô◊ö ◊ê◊†◊ô ◊û◊™◊ë◊ò◊ê, ◊û◊í◊ô◊ë ◊ï◊û◊™◊ß◊©◊®.` : '◊ñ◊î◊î ◊ê◊ï◊™◊ô ◊ë◊©◊ô◊ó◊î ◊ï◊™◊™◊û◊ß◊ì ◊ë◊†◊ô◊™◊ï◊ó ◊î◊™◊ß◊©◊ï◊®◊™ ◊©◊ú◊ô.'}

◊ì◊ë◊®◊ô◊ù ◊©◊ê◊†◊ô ◊®◊ï◊¶◊î ◊©◊™◊™◊û◊ß◊ì ◊ë◊î◊ù:
- ◊ê◊ô◊ö ◊ê◊†◊ô ◊û◊™◊ë◊ò◊ê ◊ï◊û◊™◊ß◊©◊®
- ◊û◊î ◊î◊°◊í◊†◊ï◊ü ◊î◊™◊ß◊©◊ï◊®◊™◊ô ◊©◊ú◊ô
- ◊ê◊ô◊ö ◊ê◊†◊ô ◊û◊í◊ô◊ë ◊ú◊û◊¶◊ë◊ô◊ù ◊©◊ï◊†◊ô◊ù ◊ë◊©◊ô◊ó◊î
- ◊ê◊ô◊ö ◊î◊™◊ß◊©◊ï◊®◊™ ◊©◊ú◊ô ◊û◊©◊§◊ô◊¢◊î ◊¢◊ú ◊î◊ß◊©◊® ◊î◊ñ◊î
- ◊û◊î ◊ê◊†◊ô ◊ô◊õ◊ï◊ú ◊ú◊©◊§◊® ◊ê◊ï ◊ú◊©◊†◊ï◊™
- ◊¢◊¶◊ï◊™ ◊û◊¢◊©◊ô◊ï◊™ ◊ú◊©◊ô◊§◊ï◊® ◊î◊™◊ß◊©◊ï◊®◊™ ◊©◊ú◊ô

◊ì◊ë◊® ◊ê◊ú◊ô◊ô ◊ô◊©◊ô◊®◊ï◊™ ◊ë◊í◊ï◊£ ◊©◊†◊ô, ◊ë◊ò◊ï◊ü ◊™◊ï◊û◊ö ◊ï◊û◊¢◊ï◊ì◊ì ◊õ◊û◊ï ◊û◊ê◊û◊ü ◊ê◊ô◊©◊ô. ◊õ◊™◊ï◊ë ◊ë◊¢◊ë◊®◊ô◊™ ◊ò◊ë◊¢◊ô◊™ ◊ï◊©◊ï◊ò◊§◊™, ◊ú◊ê ◊ë◊™◊®◊í◊ï◊ù. ◊™◊ü ◊ú◊ô ◊™◊ï◊ë◊†◊ï◊™ ◊û◊¢◊û◊ô◊ß◊ï◊™ ◊ê◊ë◊ú ◊ë◊ê◊ï◊§◊ü ◊©◊ê◊†◊ô ◊ê◊ï◊õ◊ú ◊ú◊ß◊ú◊ï◊ò ◊ï◊ú◊î◊§◊¢◊ô◊ú ◊ë◊ó◊ô◊ô◊ù. ◊î◊©◊™◊û◊© ◊ë◊©◊û◊ï◊™ ◊î◊ê◊û◊ô◊™◊ô◊ô◊ù ◊©◊ú ◊î◊ê◊†◊©◊ô◊ù ◊ë◊©◊ô◊ó◊î ◊õ◊©◊ê◊™◊î ◊û◊™◊ô◊ô◊ó◊° ◊ê◊ú◊ô◊î◊ù.

◊™◊û◊ú◊ô◊ú ◊î◊©◊ô◊ó◊î:
${namedTranscript}`;
                } else {
                    // Enhanced English prompt - more coach-like
                    analysisPrompt = `You are an experienced personal coach and communication psychologist who specializes in helping people understand themselves through their communication patterns. You have a warm, supportive coaching style that makes people feel understood and empowered.

The conversation you're analyzing is between ${relationshipContext}. My name is ${userName} and I want you to analyze my communication behavior and help me understand how I operate in relationships.

${selectedSpeaker ? `I am ${selectedSpeaker} in this conversation. Focus specifically on analyzing me - how I express myself, respond, and communicate.` : 'Please identify me in the conversation and focus on analyzing my communication.'}

Focus on:
- How I express myself and communicate
- My communication style and patterns
- How I respond to different situations in the conversation
- How my communication affects this relationship dynamic
- What I could improve or change
- Practical advice for better communication

Speak to me directly in second person with a supportive, encouraging tone like a personal coach would. Write in natural, flowing language that feels like a real conversation. Give me deep insights but in a way I can understand and apply in my life. Use the actual names of people in the conversation when referring to them.

Conversation transcript:
${namedTranscript}`;
                }
                
                const response = await fetch(`${BACKEND_URL}/api/analyze`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        prompt: analysisPrompt,
                        maxTokens: selectedModel === 'gpt-4' ? 4000 : 2500, // Higher limits for analysis
                        language: analysisLanguage,
                        model: selectedModel
                    })
                });
                
                if (!response.ok) {
                    let errorData;
                    try {
                        // Clone the response to avoid "body stream already read" error
                        const responseClone = response.clone();
                        errorData = await responseClone.json();
                    } catch {
                        // If JSON parsing fails, read as text
                        try {
                            const errorText = await response.text();
                            errorData = { message: errorText || 'Analysis failed' };
                        } catch {
                            errorData = { message: 'Analysis failed' };
                        }
                    }
                    throw new Error(errorData.message || 'Analysis failed');
                }
                
                const data = await response.json();
                
                document.getElementById('analysisContent').innerHTML = data.response.replace(/\n/g, '<br>');
                document.getElementById('analysisResult').classList.remove('hidden');
                document.getElementById('contextSection').classList.remove('hidden');
                
                // Auto-save if conversation already exists
                if (currentConversationId) {
                    saveConversation();
                }
                
            } catch (error) {
                console.error('Analysis error:', error);
                if (error.message.includes('fetch')) {
                    showError('Cannot connect to analysis server. Please make sure the backend server is running.');
                } else {
                    showError('Error analyzing conversation: ' + error.message);
                }
            } finally {
                hideLoading();
            }
        }

        async function continueAnalysis() {
            const contextInput = document.getElementById('contextInput').value;
            if (!contextInput.trim()) {
                showError('Please add some context or questions to continue.');
                return;
            }
            
            const userName = document.getElementById('userName').value || 'User';
            const previousAnalysis = document.getElementById('analysisContent').innerHTML.replace(/<br>/g, '\n');
            const analysisLanguage = document.getElementById('analysisLanguage').value;
            const continuePrompt = document.getElementById('continuePrompt').value;
            const relationshipType = document.getElementById('relationshipType').value;
            const customRelationship = document.getElementById('customRelationship').value;
            const selectedModel = document.getElementById('aiModel').value;
            
            // Get speaker information
            const { namedSpeakers, selectedSpeaker } = getSpeakerNames();
            const namedTranscript = createNamedTranscript();
            
            try {
                const loadingMessage = selectedModel === 'gpt-4' ? 
                    'Continuing analysis with ChatGPT-4... (this may take 10-30 seconds)' : 
                    'Continuing analysis with ChatGPT-3.5... (should be ready in 2-5 seconds)';
                showLoading(loadingMessage);
                
                let relationshipContext = '';
                if (relationshipType === 'other' && customRelationship.trim()) {
                    relationshipContext = customRelationship.trim();
                } else {
                    const relationshipMap = {
                        'romantic': analysisLanguage === 'he' ? '◊ñ◊ï◊í ◊®◊ï◊û◊†◊ò◊ô' : 'romantic partners',
                        'parent-child': analysisLanguage === 'he' ? '◊î◊ï◊®◊î ◊ï◊ô◊ú◊ì' : 'parent and child',
                        'friends': analysisLanguage === 'he' ? '◊ó◊ë◊®◊ô◊ù' : 'friends',
                        'colleagues': analysisLanguage === 'he' ? '◊¢◊û◊ô◊™◊ô◊ù ◊ú◊¢◊ë◊ï◊ì◊î' : 'work colleagues',
                        'family': analysisLanguage === 'he' ? '◊ë◊†◊ô ◊û◊©◊§◊ó◊î' : 'family members'
                    };
                    relationshipContext = relationshipMap[relationshipType] || (analysisLanguage === 'he' ? '◊ê◊†◊©◊ô◊ù' : 'people');
                }
                
                let fullPrompt;
                
                if (analysisLanguage === 'he') {
                    fullPrompt = `◊ê◊™◊î ◊û◊ê◊û◊ü ◊ê◊ô◊©◊ô ◊ï◊§◊°◊ô◊õ◊ï◊ú◊ï◊í ◊û◊†◊ï◊°◊î ◊©◊û◊û◊©◊ô◊ö ◊†◊ô◊™◊ï◊ó ◊™◊ß◊©◊ï◊®◊™. ◊ì◊ë◊® ◊ë◊¢◊ë◊®◊ô◊™ ◊ò◊ë◊¢◊ô◊™ ◊ï◊ó◊û◊î.

◊î◊†◊ô◊™◊ï◊ó ◊î◊ß◊ï◊ì◊ù ◊©◊ú◊ö:
${previousAnalysis}

◊ê◊†◊ô (${userName}) ${selectedSpeaker ? `(${selectedSpeaker} ◊ë◊©◊ô◊ó◊î)` : ''} ◊î◊ï◊°◊§◊™◊ô ◊ê◊™ ◊î◊î◊ß◊©◊®/◊î◊©◊ê◊ú◊î ◊î◊ñ◊ê◊™: "${contextInput}"

◊î◊©◊ô◊ó◊î ◊î◊û◊ß◊ï◊®◊ô◊™ ◊î◊ô◊ô◊™◊î ◊ë◊ô◊ü ${relationshipContext}. ◊ß◊ó ◊ê◊™ ◊ñ◊î ◊ë◊ó◊©◊ë◊ï◊ü.

◊ê◊†◊ê ◊î◊™◊ô◊ô◊ó◊° ◊ú◊©◊ê◊ú◊î ◊ê◊ï ◊î◊î◊ß◊©◊® ◊©◊ú◊ô ◊ï◊™◊ü ◊™◊ï◊ë◊†◊ï◊™ ◊†◊ï◊°◊§◊ï◊™. ${selectedSpeaker ? `◊î◊û◊©◊ö ◊ú◊î◊™◊û◊ß◊ì ◊ë◊†◊ô◊™◊ï◊ó ◊©◊ú◊ô ◊õ${selectedSpeaker}.` : ''} ◊©◊û◊ï◊® ◊¢◊ú ◊î◊ò◊ï◊ü ◊î◊ê◊ô◊©◊ô ◊ï◊î◊™◊ï◊û◊ö ◊ï◊§◊†◊î ◊ê◊ú◊ô◊ô ◊ë◊í◊ï◊£ ◊©◊†◊ô. ◊î◊©◊™◊û◊© ◊ë◊©◊û◊ï◊™ ◊î◊ê◊û◊ô◊™◊ô◊ô◊ù ◊©◊ú ◊î◊ê◊†◊©◊ô◊ù ◊ë◊©◊ô◊ó◊î.

◊î◊™◊û◊ú◊ô◊ú ◊î◊û◊ß◊ï◊®◊ô:
${namedTranscript}`;
                } else {
                    fullPrompt = `You are an experienced personal coach and psychologist continuing a communication analysis. Speak naturally and warmly.

Previous analysis:
${previousAnalysis}

I (${userName}) ${selectedSpeaker ? `(${selectedSpeaker} in the conversation)` : ''} have added this context/question: "${contextInput}"

The original conversation was between ${relationshipContext}. Keep this in mind.

${continuePrompt}

${selectedSpeaker ? `Continue focusing on my analysis as ${selectedSpeaker}.` : ''} Use the actual names of people in the conversation when referring to them.

Original transcript:
${namedTranscript}`;
                }
                
                const response = await fetch(`${BACKEND_URL}/api/analyze`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        prompt: fullPrompt,
                        maxTokens: selectedModel === 'gpt-4' ? 2500 : 1500, // Higher limits for follow-ups
                        language: analysisLanguage,
                        model: selectedModel
                    })
                });
                
                if (!response.ok) {
                    let errorData;
                    try {
                        // Clone the response to avoid "body stream already read" error
                        const responseClone = response.clone();
                        errorData = await responseClone.json();
                    } catch {
                        // If JSON parsing fails, read as text
                        try {
                            const errorText = await response.text();
                            errorData = { message: errorText || 'Continued analysis failed' };
                        } catch {
                            errorData = { message: 'Continued analysis failed' };
                        }
                    }
                    throw new Error(errorData.message || 'Continued analysis failed');
                }
                
                const data = await response.json();
                
                const currentContent = document.getElementById('analysisContent').innerHTML;
                const followUpLabel = analysisLanguage === 'he' ? '◊î◊û◊©◊ö:' : 'Follow-up:';
                document.getElementById('analysisContent').innerHTML = currentContent + '<br><br><strong>' + followUpLabel + '</strong><br>' + data.response.replace(/\n/g, '<br>');
                document.getElementById('contextInput').value = '';
                
                // Auto-save if conversation already exists
                if (currentConversationId) {
                    saveConversation();
                }
                
            } catch (error) {
                console.error('Continue analysis error:', error);
                if (error.message.includes('fetch')) {
                    showError('Cannot connect to analysis server. Please make sure the backend server is running.');
                } else {
                    showError('Error continuing analysis: ' + error.message);
                }
            } finally {
                hideLoading();
            }
        }

        function getSelectedSpeaker() {
            const selectedRadio = document.querySelector('input[name="isMe"]:checked');
            if (selectedRadio) {
                const speakerIndex = parseInt(selectedRadio.value);
                const speakerInputs = document.querySelectorAll('.speaker-name-input');
                if (speakerInputs[speakerIndex]) {
                    return speakerInputs[speakerIndex].value || speakers[speakerIndex];
                }
            }
            return null;
        }

        function getSpeakerNames() {
            const speakerInputs = document.querySelectorAll('.speaker-name-input');
            const namedSpeakers = {};
            const selectedSpeaker = getSelectedSpeaker();
            
            speakerInputs.forEach((input, index) => {
                const originalSpeaker = speakers[index];
                const customName = input.value.trim();
                if (customName && customName !== originalSpeaker) {
                    namedSpeakers[originalSpeaker] = customName;
                }
            });
            
            return { namedSpeakers, selectedSpeaker };
        }

        function createNamedTranscript() {
            const { namedSpeakers } = getSpeakerNames();
            let namedTranscript = currentTranscript;
            
            // Replace speaker labels with custom names
            Object.keys(namedSpeakers).forEach(originalSpeaker => {
                const customName = namedSpeakers[originalSpeaker];
                const regex = new RegExp(`^${originalSpeaker.replace(/[.*+?^${}()|[\]\\]/g, '\\        function getSelectedSpeaker() {
            const selectedRadio = document.querySelector('input[name="isMe"]:checked');
            if (selectedRadio) {
                const speakerIndex = parseInt(selectedRadio.value);
                const speakerInputs = document.querySelectorAll('.speaker-name-input');
                if (speakerInputs[speakerIndex]) {
                    return speakerInputs[speakerIndex].value || speakers[speakerIndex];
                }
            }
            return null;
        }')}:`, 'gm');
                namedTranscript = namedTranscript.replace(regex, `${customName}:`);
            });
            
            return namedTranscript;
        }

        function showLoading(message) {
            // Remove existing loading indicators
            document.querySelectorAll('.loading').forEach(el => el.remove());
            
            // Create loading indicator
            const loadingDiv = document.createElement('div');
            loadingDiv.className = 'loading';
            loadingDiv.innerHTML = `
                <div class="spinner"></div>
                <span>${message}</span>
            `;
            
            // Add to main card
            document.querySelector('.main-card').appendChild(loadingDiv);
        }

        function hideLoading() {
            document.querySelectorAll('.loading').forEach(el => el.remove());
        }

        function showError(message) {
            // Remove existing error messages
            document.querySelectorAll('.error').forEach(el => el.remove());
            
            // Create error message
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error';
            errorDiv.textContent = message;
            
            // Add to main card at the top
            const mainCard = document.querySelector('.main-card');
            mainCard.insertBefore(errorDiv, mainCard.firstChild);
            
            // Auto-remove after 5 seconds
            setTimeout(() => {
                errorDiv.remove();
            }, 5000);
        }

        // Conversation Management Functions
        function loadSavedConversations() {
            try {
                const saved = JSON.parse(localStorage.getItem('reflectAI_conversations') || '[]');
                savedConversations = saved;
                renderSavedConversations();
            } catch (error) {
                console.error('Error loading saved conversations:', error);
                savedConversations = [];
            }
        }

        function saveConversationsToStorage() {
            try {
                localStorage.setItem('reflectAI_conversations', JSON.stringify(savedConversations));
            } catch (error) {
                console.error('Error saving conversations:', error);
                showError('Failed to save conversations. Storage may be full.');
            }
        }

        function generateConversationTitle(transcript) {
            const lines = transcript.split('\n').filter(line => line.trim());
            if (lines.length === 0) return 'Empty Conversation';
            
            // Try to find the first meaningful line
            let firstLine = lines[0];
            if (firstLine.includes(':')) {
                firstLine = firstLine.split(':')[1].trim();
            }
            
            // Truncate and clean up
            let title = firstLine.substring(0, 50);
            if (firstLine.length > 50) {
                title += '...';
            }
            
            return title || 'Untitled Conversation';
        }

        function saveConversation() {
            if (!currentTranscript.trim()) {
                showError('No conversation to save.');
                return;
            }

            const conversationTitle = generateConversationTitle(currentTranscript);
            const now = new Date();
            
            const conversation = {
                id: currentConversationId || Date.now().toString(),
                title: conversationTitle,
                transcript: currentTranscript,
                speakers: speakers,
                method: currentMethod,
                userName: document.getElementById('userName').value || 'User',
                conversationLanguage: document.getElementById('conversationLanguage').value,
                analysisLanguage: document.getElementById('analysisLanguage').value,
                relationshipType: document.getElementById('relationshipType').value,
                customRelationship: document.getElementById('customRelationship').value,
                aiModel: document.getElementById('aiModel').value,
                createdAt: now.toISOString(),
                updatedAt: now.toISOString(),
                summary: document.getElementById('summaryContent').innerHTML || null,
                analysis: document.getElementById('analysisContent').innerHTML || null
            };

            // Check if conversation already exists
            const existingIndex = savedConversations.findIndex(c => c.id === conversation.id);
            
            if (existingIndex >= 0) {
                // Update existing conversation
                savedConversations[existingIndex] = conversation;
                showSuccess('üíæ Conversation updated successfully!');
            } else {
                // Add new conversation
                savedConversations.unshift(conversation);
                showSuccess('üíæ Conversation saved successfully!');
            }

            currentConversationId = conversation.id;
            saveConversationsToStorage();
            renderSavedConversations();
            updateCurrentConversationIndicator();
        }

        function loadConversation(conversationId) {
            const conversation = savedConversations.find(c => c.id === conversationId);
            if (!conversation) {
                showError('Conversation not found.');
                return;
            }

            // Load conversation data
            currentTranscript = conversation.transcript;
            speakers = conversation.speakers || [];
            currentConversationId = conversation.id;
            
            // Update UI settings
            document.getElementById('userName').value = conversation.userName || '';
            document.getElementById('conversationLanguage').value = conversation.conversationLanguage || 'en';
            document.getElementById('analysisLanguage').value = conversation.analysisLanguage || 'en';
            document.getElementById('relationshipType').value = conversation.relationshipType || 'friends';
            document.getElementById('customRelationship').value = conversation.customRelationship || '';
            document.getElementById('aiModel').value = conversation.aiModel || 'gpt-3.5-turbo';
            updateModelTooltip();
            
            // Display transcript
            displayTranscript(currentTranscript);
            
            // Load summary and analysis if available
            if (conversation.summary) {
                document.getElementById('summaryContent').innerHTML = conversation.summary;
                document.getElementById('summaryResult').classList.remove('hidden');
            }
            
            if (conversation.analysis) {
                document.getElementById('analysisContent').innerHTML = conversation.analysis;
                document.getElementById('analysisResult').classList.remove('hidden');
                document.getElementById('contextSection').classList.remove('hidden');
            }
            
            // Update method selection
            document.querySelectorAll('.method-btn').forEach(btn => {
                btn.classList.remove('active');
                if (btn.dataset.method === conversation.method) {
                    btn.classList.add('active');
                }
            });
            
            currentMethod = conversation.method;
            document.querySelectorAll('.input-section').forEach(section => {
                section.classList.add('hidden');
            });
            document.getElementById(currentMethod + 'Section').classList.remove('hidden');
            
            enableActionButtons();
            updateCurrentConversationIndicator();
            
            showSuccess(`üìÇ Loaded conversation: ${conversation.title}`);
        }

        function deleteConversation(conversationId) {
            if (!confirm('Are you sure you want to delete this conversation? This action cannot be undone.')) {
                return;
            }

            const conversationIndex = savedConversations.findIndex(c => c.id === conversationId);
            if (conversationIndex >= 0) {
                const deletedConversation = savedConversations.splice(conversationIndex, 1)[0];
                
                // If we're deleting the current conversation, reset
                if (currentConversationId === conversationId) {
                    startNewConversation();
                }
                
                saveConversationsToStorage();
                renderSavedConversations();
                showSuccess(`üóëÔ∏è Deleted conversation: ${deletedConversation.title}`);
            }
        }

        function startNewConversation() {
            resetTranscript();
            
            // Reset form fields
            document.getElementById('conversationText').value = '';
            document.getElementById('audioFile').value = '';
            
            // Hide audio playback
            document.getElementById('audioPlayback').classList.add('hidden');
            
            // Reset to record method
            document.querySelectorAll('.method-btn').forEach(btn => {
                btn.classList.remove('active');
                if (btn.dataset.method === 'record') {
                    btn.classList.add('active');
                }
            });
            
            currentMethod = 'record';
            document.querySelectorAll('.input-section').forEach(section => {
                section.classList.add('hidden');
            });
            document.getElementById('recordSection').classList.remove('hidden');
            
            showSuccess('üÜï Started new conversation');
        }

        function renderSavedConversations() {
            const listContainer = document.getElementById('savedConversationsList');
            
            if (savedConversations.length === 0) {
                listContainer.innerHTML = '<p style="color: #666; text-align: center; padding: 20px;">No saved conversations yet...</p>';
                return;
            }
            
            listContainer.innerHTML = '';
            
            savedConversations.forEach(conversation => {
                const conversationItem = document.createElement('div');
                conversationItem.className = 'conversation-item';
                if (conversation.id === currentConversationId) {
                    conversationItem.style.borderColor = '#28a745';
                    conversationItem.style.borderWidth = '3px';
                }
                
                const methodBadge = {
                    record: '<span class="conversation-badge recorded">üéôÔ∏è Recorded</span>',
                    upload: '<span class="conversation-badge uploaded">üìÅ Uploaded</span>',
                    type: '<span class="conversation-badge typed">‚úçÔ∏è Typed</span>'
                };
                
                const date = new Date(conversation.createdAt).toLocaleString();
                const preview = conversation.transcript.substring(0, 100) + (conversation.transcript.length > 100 ? '...' : '');
                
                conversationItem.innerHTML = `
                    <div class="conversation-header">
                        <div class="conversation-title">${conversation.title}</div>
                        <div class="conversation-date">${date}</div>
                    </div>
                    <div style="margin-bottom: 10px;">
                        ${methodBadge[conversation.method] || ''}
                        <span style="color: #666; font-size: 14px;">${conversation.userName}</span>
                    </div>
                    <div class="conversation-preview">${preview}</div>
                    <div class="conversation-actions">
                        <button class="conversation-action-btn load" onclick="loadConversation('${conversation.id}')">
                            üìÇ Load
                        </button>
                        <button class="conversation-action-btn delete" onclick="deleteConversation('${conversation.id}')">
                            üóëÔ∏è Delete
                        </button>
                    </div>
                `;
                
                listContainer.appendChild(conversationItem);
            });
        }

        function updateCurrentConversationIndicator() {
            const indicator = document.querySelector('.current-conversation-indicator');
            if (!indicator) return;
            
            if (currentConversationId) {
                const conversation = savedConversations.find(c => c.id === currentConversationId);
                if (conversation) {
                    indicator.innerHTML = `
                        <strong>üìù Current Conversation:</strong> ${conversation.title}
                        <span style="color: #666; margin-left: 10px;">Last updated: ${new Date(conversation.updatedAt).toLocaleString()}</span>
                    `;
                    indicator.classList.add('active');
                } else {
                    indicator.classList.remove('active');
                }
            } else {
                indicator.classList.remove('active');
            }
        }

        async function testOpenAIConnection() {
            console.log('üß™ Test OpenAI Connection button clicked');
            
            try {
                showLoading('Testing OpenAI connection...');
                
                const response = await fetch(`${BACKEND_URL}/api/test`);
                const data = await response.json();
                
                if (response.ok) {
                    showSuccess(`‚úÖ OpenAI connection working! Test response: "${data.test_response}"`);
                    console.log('OpenAI test result:', data);
                } else {
                    showError(`‚ùå OpenAI test failed: ${data.message}`);
                    console.error('OpenAI test error:', data);
                }
                
            } catch (error) {
                showError(`‚ùå Connection test failed: ${error.message}`);
                console.error('Test error:', error);
            } finally {
                hideLoading();
            }
        }

        function showSuccess(message) {
            // Remove existing success messages
            document.querySelectorAll('.success').forEach(el => el.remove());
            
            // Create success message
            const successDiv = document.createElement('div');
            successDiv.className = 'success';
            successDiv.textContent = message;
            
            // Add to main card at the top
            const mainCard = document.querySelector('.main-card');
            mainCard.insertBefore(successDiv, mainCard.firstChild);
            
            // Auto-remove after 5 seconds
            setTimeout(() => {
                successDiv.remove();
            }, 5000);
        }
    </script>
</body>
</html>